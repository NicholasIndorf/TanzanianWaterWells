{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset('penguins')\n",
    "penguins = penguins.dropna()\n",
    "y = penguins.pop('species')\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    penguins, y, test_size=0.5, random_state=42)\n",
    "X_train_nums = X_train.select_dtypes('float64')\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "ss.fit(X_train_nums)\n",
    "nums_df = pd.DataFrame(ss.transform(X_train_nums),\n",
    "                      index=X_train_nums.index)\n",
    "X_train_cat = X_train.select_dtypes('object')\n",
    "\n",
    "ohe = OneHotEncoder(\n",
    "    drop='first',\n",
    "    sparse=False)\n",
    "\n",
    "dums = ohe.fit_transform(X_train_cat)\n",
    "dums_df = pd.DataFrame(dums,\n",
    "                       columns=ohe.get_feature_names(),\n",
    "                       index=X_train_cat.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>x0_Dream</th>\n",
       "      <th>x0_Torgersen</th>\n",
       "      <th>x1_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.362748</td>\n",
       "      <td>0.903276</td>\n",
       "      <td>-0.472344</td>\n",
       "      <td>-0.094599</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.973499</td>\n",
       "      <td>-0.977375</td>\n",
       "      <td>1.408317</td>\n",
       "      <td>2.512546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.725152</td>\n",
       "      <td>0.445820</td>\n",
       "      <td>-0.472344</td>\n",
       "      <td>-1.185963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>-1.221387</td>\n",
       "      <td>1.360731</td>\n",
       "      <td>-0.255345</td>\n",
       "      <td>-0.882806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.030757</td>\n",
       "      <td>0.954104</td>\n",
       "      <td>-0.110678</td>\n",
       "      <td>-0.519018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.297960</td>\n",
       "      <td>1.004932</td>\n",
       "      <td>-0.400011</td>\n",
       "      <td>-0.822175</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-1.316816</td>\n",
       "      <td>1.157417</td>\n",
       "      <td>-1.268008</td>\n",
       "      <td>-0.397756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>-0.839667</td>\n",
       "      <td>0.293335</td>\n",
       "      <td>-0.617010</td>\n",
       "      <td>-1.246594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0.267318</td>\n",
       "      <td>-1.079032</td>\n",
       "      <td>1.335984</td>\n",
       "      <td>0.936132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>-1.145043</td>\n",
       "      <td>-0.062464</td>\n",
       "      <td>-1.485007</td>\n",
       "      <td>-1.276910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3  x0_Dream  x0_Torgersen  x1_Male\n",
       "160  0.362748  0.903276 -0.472344 -0.094599       1.0           0.0      0.0\n",
       "237  0.973499 -0.977375  1.408317  2.512546       0.0           0.0      1.0\n",
       "2   -0.725152  0.445820 -0.472344 -1.185963       0.0           1.0      0.0\n",
       "121 -1.221387  1.360731 -0.255345 -0.882806       0.0           1.0      1.0\n",
       "179  1.030757  0.954104 -0.110678 -0.519018       1.0           0.0      1.0\n",
       "..        ...       ...       ...       ...       ...           ...      ...\n",
       "194  1.297960  1.004932 -0.400011 -0.822175       1.0           0.0      1.0\n",
       "77  -1.316816  1.157417 -1.268008 -0.397756       0.0           1.0      1.0\n",
       "112 -0.839667  0.293335 -0.617010 -1.246594       0.0           0.0      0.0\n",
       "277  0.267318 -1.079032  1.335984  0.936132       0.0           0.0      1.0\n",
       "108 -1.145043 -0.062464 -1.485007 -1.276910       0.0           0.0      0.0\n",
       "\n",
       "[166 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clean = pd.concat([nums_df, dums_df], axis=1)\n",
    "X_train_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_nums = X_test.select_dtypes('float64')\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "ss.fit(X_test_nums)\n",
    "nums_df = pd.DataFrame(ss.transform(X_test_nums),\n",
    "                      index=X_test_nums.index)\n",
    "X_test_cat = X_test.select_dtypes('object')\n",
    "\n",
    "ohe = OneHotEncoder(\n",
    "    drop='first',\n",
    "    sparse=False)\n",
    "\n",
    "dums = ohe.fit_transform(X_test_cat)\n",
    "dums_df = pd.DataFrame(dums,\n",
    "                       columns=ohe.get_feature_names(),\n",
    "                       index=X_test_cat.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>x0_Dream</th>\n",
       "      <th>x0_Torgersen</th>\n",
       "      <th>x1_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.773744</td>\n",
       "      <td>-0.257901</td>\n",
       "      <td>-1.584752</td>\n",
       "      <td>-1.196636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0.531460</td>\n",
       "      <td>-1.327003</td>\n",
       "      <td>1.527156</td>\n",
       "      <td>0.880352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>-0.315159</td>\n",
       "      <td>0.963929</td>\n",
       "      <td>-0.382424</td>\n",
       "      <td>-0.238026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1.042959</td>\n",
       "      <td>0.047556</td>\n",
       "      <td>-0.170249</td>\n",
       "      <td>-0.653424</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-0.491537</td>\n",
       "      <td>0.505743</td>\n",
       "      <td>-0.594600</td>\n",
       "      <td>-0.174119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1.166424</td>\n",
       "      <td>-1.021546</td>\n",
       "      <td>1.102804</td>\n",
       "      <td>1.040120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.637288</td>\n",
       "      <td>-1.123365</td>\n",
       "      <td>1.244255</td>\n",
       "      <td>0.976213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.443271</td>\n",
       "      <td>0.709381</td>\n",
       "      <td>-0.736050</td>\n",
       "      <td>-0.941007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.513822</td>\n",
       "      <td>-0.919726</td>\n",
       "      <td>1.032079</td>\n",
       "      <td>1.231842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0.284530</td>\n",
       "      <td>-1.785190</td>\n",
       "      <td>0.961354</td>\n",
       "      <td>0.592769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3  x0_Dream  x0_Torgersen  x1_Male\n",
       "30  -0.773744 -0.257901 -1.584752 -1.196636       1.0           0.0      0.0\n",
       "317  0.531460 -1.327003  1.527156  0.880352       0.0           0.0      0.0\n",
       "79  -0.315159  0.963929 -0.382424 -0.238026       0.0           1.0      1.0\n",
       "201  1.042959  0.047556 -0.170249 -0.653424       1.0           0.0      0.0\n",
       "63  -0.491537  0.505743 -0.594600 -0.174119       0.0           0.0      1.0\n",
       "..        ...       ...       ...       ...       ...           ...      ...\n",
       "330  1.166424 -1.021546  1.102804  1.040120       0.0           0.0      0.0\n",
       "310  0.637288 -1.123365  1.244255  0.976213       0.0           0.0      0.0\n",
       "170  0.443271  0.709381 -0.736050 -0.941007       1.0           0.0      0.0\n",
       "229  0.513822 -0.919726  1.032079  1.231842       0.0           0.0      1.0\n",
       "232  0.284530 -1.785190  0.961354  0.592769       0.0           0.0      0.0\n",
       "\n",
       "[167 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_clean = pd.concat([nums_df, dums_df], axis=1)\n",
    "X_test_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating Pipelines for each column type: numeric, categorical with under 10 categories, categorical with over 10 categories\n",
    "\n",
    "num_col_pipe = Pipeline(steps = [\n",
    "    ('mm', MinMaxScaler())\n",
    "])\n",
    "\n",
    "sm_cat_col_pipe = Pipeline(steps = [\n",
    "    ('ohe', OneHotEncoder(drop = 'first',\n",
    "                          sparse = False \n",
    "                         )\n",
    "    )\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Note About IterativeImputer text\n",
    "\n",
    "This is straight up copied from : https://machinelearningmastery.com/iterative-imputation-for-missing-values-in-machine-learning/\n",
    "So if we use any of the below we need to rewrite and cite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By default, imputation is performed in ascending order from the feature\n",
    "# with the least missing values to the feature with the most.\n",
    "# here are the strategy options: strategies = ['ascending', 'descending', 'roman', 'arabic', 'random']\n",
    "\n",
    "#Max_iterations: It is possible that a large number of iterations may begin to bias or skew the\n",
    "# estimate and that few iterations may be preferred. The number of iterations of the procedure can be \n",
    "# specified via the “max_iter” argument. Default value is 10\n",
    "\n",
    "lrg_cat_col_pipe = Pipeline(steps = [\n",
    "    ('ii', IterativeImputer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring some placeholder lists \n",
    "num_cols = []\n",
    "sm_cat_cols = []\n",
    "lrg_cat_cols = []\n",
    "\n",
    "col_trans = ColumnTransformer(transformers=[\n",
    "    ('numeric', num_col_pipe, num_cols),\n",
    "    ('small_cat', sm_cat_col_pipe, sm_cat_cols),\n",
    "    ('large_cat', lrg_cat_col_pipe, lrg_cat_cols )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe_knn = Pipeline(steps =[\n",
    "    ('col_trans', col_trans),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {'knn':KNeighborsClassifier(), 'lr':LogisticRegression()}\n",
    "\n",
    "def basic_model_tests(X, y, test_dict):\n",
    "    '''Takes in X and y data as well as dictionary of name:test entries to run'''\n",
    "    scores = []\n",
    "    for key, value in test_dict.items():\n",
    "        test_model_loop = Pipeline(steps=[\n",
    "            (key, value)\n",
    "        ])\n",
    "        test_model_loop.fit(X, y)\n",
    "        score = test_model_loop.score(X, y)\n",
    "        scores.append({'name':key, 'type':value, 'score':score})\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = basic_model_tests(X_train_clean, y_train, test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'knn', 'type': KNeighborsClassifier(), 'score': 0.9939759036144579}, {'name': 'lr', 'type': LogisticRegression(), 'score': 1.0}]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [{'name':'knn', 'type': KNeighborsClassifier(), 'params':{'knn__n_neighbors': [3, 5, 7], 'knn__p': [1, 2, 3]}},\n",
    "            {'name': 'lr', 'type': LogisticRegression(), 'params':{'lr__fit_intercept':[False], 'lr__C':[1, 1000, 1e12],\n",
    "                                                                  'lr__solver':['liblinear','newton-cg', 'lbfgs']}}]\n",
    "#fit_intercept=False, C= 1e12, solver='liblinear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "LogisticRegression()\n"
     ]
    }
   ],
   "source": [
    "for x in test_list:\n",
    "    print(x['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_tests(X, y, test_list):\n",
    "    '''Takes in X and y data as well as a list of dictionaries'''\n",
    "    scores = []\n",
    "    for x in test_list:\n",
    "        test_model_loop = Pipeline(steps=[\n",
    "            (x['name'], x['type'])\n",
    "        ])\n",
    "        test_model_loop.fit(X, y)\n",
    "#         score = test_model_loop.score(X, y)\n",
    "#         scores.append({'name':x['name'], 'type':x['type'], 'score':score})\n",
    "        \n",
    "        gs_pipe = GridSearchCV(estimator=test_model_loop, param_grid=x['params'])\n",
    "        gs_pipe.fit(X,y)\n",
    "        scores.append(gs_pipe.cv_results_)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       0.002404      0.000494         0.002791        0.000744   \n",
      "1       0.002199      0.000401         0.003002        0.000011   \n",
      "2       0.002195      0.000399         0.002801        0.000400   \n",
      "3       0.001999      0.000003         0.002800        0.000400   \n",
      "4       0.002002      0.000005         0.002801        0.000401   \n",
      "5       0.002204      0.000402         0.002598        0.000491   \n",
      "6       0.002002      0.000009         0.002599        0.000486   \n",
      "7       0.002200      0.000404         0.002203        0.000392   \n",
      "8       0.001998      0.000003         0.002999        0.000015   \n",
      "\n",
      "  param_knn__n_neighbors param_knn__p                                params  \\\n",
      "0                      3            1  {'knn__n_neighbors': 3, 'knn__p': 1}   \n",
      "1                      3            2  {'knn__n_neighbors': 3, 'knn__p': 2}   \n",
      "2                      3            3  {'knn__n_neighbors': 3, 'knn__p': 3}   \n",
      "3                      5            1  {'knn__n_neighbors': 5, 'knn__p': 1}   \n",
      "4                      5            2  {'knn__n_neighbors': 5, 'knn__p': 2}   \n",
      "5                      5            3  {'knn__n_neighbors': 5, 'knn__p': 3}   \n",
      "6                      7            1  {'knn__n_neighbors': 7, 'knn__p': 1}   \n",
      "7                      7            2  {'knn__n_neighbors': 7, 'knn__p': 2}   \n",
      "8                      7            3  {'knn__n_neighbors': 7, 'knn__p': 3}   \n",
      "\n",
      "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
      "0                1.0                1.0           0.969697           1.000000   \n",
      "1                1.0                1.0           0.969697           1.000000   \n",
      "2                1.0                1.0           0.969697           1.000000   \n",
      "3                1.0                1.0           0.969697           1.000000   \n",
      "4                1.0                1.0           0.969697           1.000000   \n",
      "5                1.0                1.0           0.969697           1.000000   \n",
      "6                1.0                1.0           0.969697           0.969697   \n",
      "7                1.0                1.0           0.969697           0.969697   \n",
      "8                1.0                1.0           0.969697           1.000000   \n",
      "\n",
      "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0                1.0         0.993939        0.012121                1  \n",
      "1                1.0         0.993939        0.012121                1  \n",
      "2                1.0         0.993939        0.012121                1  \n",
      "3                1.0         0.993939        0.012121                1  \n",
      "4                1.0         0.993939        0.012121                1  \n",
      "5                1.0         0.993939        0.012121                1  \n",
      "6                1.0         0.987879        0.014845                8  \n",
      "7                1.0         0.987879        0.014845                8  \n",
      "8                1.0         0.993939        0.012121                1  \n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_lr__C  \\\n",
      "0       0.002002      0.000013         0.001800        0.000406           1   \n",
      "1       0.007369      0.000462         0.001198        0.000404           1   \n",
      "2       0.005636      0.000526         0.001401        0.000499           1   \n",
      "3       0.002593      0.000494         0.001000        0.000001        1000   \n",
      "4       0.009239      0.000388         0.001404        0.000492        1000   \n",
      "5       0.008010      0.001289         0.001401        0.000489        1000   \n",
      "6       0.002006      0.000008         0.001196        0.000399       1e+12   \n",
      "7       0.010620      0.000592         0.001206        0.000401       1e+12   \n",
      "8       0.006600      0.000489         0.001287        0.000398       1e+12   \n",
      "\n",
      "  param_lr__fit_intercept param_lr__solver  \\\n",
      "0                   False        liblinear   \n",
      "1                   False        newton-cg   \n",
      "2                   False            lbfgs   \n",
      "3                   False        liblinear   \n",
      "4                   False        newton-cg   \n",
      "5                   False            lbfgs   \n",
      "6                   False        liblinear   \n",
      "7                   False        newton-cg   \n",
      "8                   False            lbfgs   \n",
      "\n",
      "                                              params  split0_test_score  \\\n",
      "0  {'lr__C': 1, 'lr__fit_intercept': False, 'lr__...                1.0   \n",
      "1  {'lr__C': 1, 'lr__fit_intercept': False, 'lr__...                1.0   \n",
      "2  {'lr__C': 1, 'lr__fit_intercept': False, 'lr__...                1.0   \n",
      "3  {'lr__C': 1000, 'lr__fit_intercept': False, 'l...                1.0   \n",
      "4  {'lr__C': 1000, 'lr__fit_intercept': False, 'l...                1.0   \n",
      "5  {'lr__C': 1000, 'lr__fit_intercept': False, 'l...                1.0   \n",
      "6  {'lr__C': 1000000000000.0, 'lr__fit_intercept'...                1.0   \n",
      "7  {'lr__C': 1000000000000.0, 'lr__fit_intercept'...                1.0   \n",
      "8  {'lr__C': 1000000000000.0, 'lr__fit_intercept'...                1.0   \n",
      "\n",
      "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
      "0                1.0           0.969697           0.969697           1.000000   \n",
      "1                1.0           0.969697           0.969697           1.000000   \n",
      "2                1.0           0.969697           0.969697           1.000000   \n",
      "3                1.0           0.969697           1.000000           1.000000   \n",
      "4                1.0           0.969697           1.000000           1.000000   \n",
      "5                1.0           0.969697           1.000000           1.000000   \n",
      "6                1.0           0.969697           1.000000           1.000000   \n",
      "7                1.0           0.969697           1.000000           0.969697   \n",
      "8                1.0           0.969697           1.000000           0.969697   \n",
      "\n",
      "   mean_test_score  std_test_score  rank_test_score  \n",
      "0         0.987879        0.014845                5  \n",
      "1         0.987879        0.014845                5  \n",
      "2         0.987879        0.014845                5  \n",
      "3         0.993939        0.012121                1  \n",
      "4         0.993939        0.012121                1  \n",
      "5         0.993939        0.012121                1  \n",
      "6         0.993939        0.012121                1  \n",
      "7         0.987879        0.014845                5  \n",
      "8         0.987879        0.014845                5  \n"
     ]
    }
   ],
   "source": [
    "scores = model_tests(X_train_clean, y_train, test_list)\n",
    "\n",
    "\n",
    "for x in scores:\n",
    "    \n",
    "    print(pd.DataFrame(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating Pipelines for each column type: numeric, categorical with under 10 categories, categorical with over 10 categories\n",
    "\n",
    "num_col_pipe = Pipeline(steps = [\n",
    "    ('mm', MinMaxScaler())\n",
    "])\n",
    "\n",
    "sm_cat_col_pipe = Pipeline(steps = [\n",
    "    ('ohe', OneHotEncoder(drop = 'first',\n",
    "                          sparse = False \n",
    "                         )\n",
    "    )\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Note About IterativeImputer text\n",
    "\n",
    "This is straight up copied from : https://machinelearningmastery.com/iterative-imputation-for-missing-values-in-machine-learning/\n",
    "So if we use any of the below we need to rewrite and cite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By default, imputation is performed in ascending order from the feature\n",
    "# with the least missing values to the feature with the most.\n",
    "# here are the strategy options: strategies = ['ascending', 'descending', 'roman', 'arabic', 'random']\n",
    "\n",
    "#Max_iterations: It is possible that a large number of iterations may begin to bias or skew the\n",
    "# estimate and that few iterations may be preferred. The number of iterations of the procedure can be \n",
    "# specified via the “max_iter” argument. Default value is 10\n",
    "\n",
    "lrg_cat_col_pipe = Pipeline(steps = [\n",
    "    ('ii', IterativeImputer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating Pipelines for each column type: numeric, categorical with under 10 categories, categorical with over 10 categories\n",
    "\n",
    "num_col_pipe = Pipeline(steps = [\n",
    "    ('mm', MinMaxScaler())\n",
    "])\n",
    "\n",
    "sm_cat_col_pipe = Pipeline(steps = [\n",
    "    ('ohe', OneHotEncoder(drop = 'first',\n",
    "                          sparse = False \n",
    "                         )\n",
    "    )\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Note About IterativeImputer text\n",
    "\n",
    "This is straight up copied from : https://machinelearningmastery.com/iterative-imputation-for-missing-values-in-machine-learning/\n",
    "So if we use any of the below we need to rewrite and cite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By default, imputation is performed in ascending order from the feature\n",
    "# with the least missing values to the feature with the most.\n",
    "# here are the strategy options: strategies = ['ascending', 'descending', 'roman', 'arabic', 'random']\n",
    "\n",
    "#Max_iterations: It is possible that a large number of iterations may begin to bias or skew the\n",
    "# estimate and that few iterations may be preferred. The number of iterations of the procedure can be \n",
    "# specified via the “max_iter” argument. Default value is 10\n",
    "\n",
    "lrg_cat_col_pipe = Pipeline(steps = [\n",
    "    ('ii', IterativeImputer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring some placeholder lists \n",
    "num_cols = []\n",
    "sm_cat_cols = []\n",
    "lrg_cat_cols = []\n",
    "\n",
    "col_trans = ColumnTransformer(transformers=[\n",
    "    ('numeric', num_col_pipe, num_cols),\n",
    "    ('small_cat', sm_cat_col_pipe, sm_cat_cols),\n",
    "    ('large_cat', lrg_cat_col_pipe, lrg_cat_cols )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe_knn = Pipeline(steps =[\n",
    "    ('col_trans', col_trans),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {'knn':KNeighborsClassifier(), 'lr':LogisticRegression()}\n",
    "\n",
    "def basic_model_tests(X, y, test_dict):\n",
    "    '''Takes in X and y data as well as dictionary of name:test entries to run'''\n",
    "    scores = []\n",
    "    for key, value in test_dict.items():\n",
    "        test_model_loop = Pipeline(steps=[\n",
    "            (key, value)\n",
    "        ])\n",
    "        test_model_loop.fit(X, y)\n",
    "        score = test_model_loop.score(X, y)\n",
    "        scores.append({'name':key, 'type':value, 'score':score})\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = basic_model_tests(X_train_clean, y_train, test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'knn', 'type': KNeighborsClassifier(), 'score': 0.9939759036144579}, {'name': 'lr', 'type': LogisticRegression(), 'score': 1.0}]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [{'name':'knn', 'type': KNeighborsClassifier(), 'params':{'knn__n_neighbors': [3, 5, 7], 'knn__p': [1, 2, 3]}},\n",
    "            {'name': 'lr', 'type': LogisticRegression(), 'params':{'lr__fit_intercept':[False], 'lr__C':[1, 1000, 1e12],\n",
    "                                                                  'lr__solver':['liblinear','newton-cg', 'lbfgs']}}]\n",
    "#fit_intercept=False, C= 1e12, solver='liblinear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "LogisticRegression()\n"
     ]
    }
   ],
   "source": [
    "for x in test_list:\n",
    "    print(x['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_tests(X, y, test_list):\n",
    "    '''Takes in X and y data as well as a list of dictionaries'''\n",
    "    scores = []\n",
    "    for x in test_list:\n",
    "        test_model_loop = Pipeline(steps=[\n",
    "            (x['name'], x['type'])\n",
    "        ])\n",
    "        test_model_loop.fit(X, y)\n",
    "#         score = test_model_loop.score(X, y)\n",
    "#         scores.append({'name':x['name'], 'type':x['type'], 'score':score})\n",
    "        \n",
    "        gs_pipe = GridSearchCV(estimator=test_model_loop, param_grid=x['params'])\n",
    "        gs_pipe.fit(X,y)\n",
    "        scores.append(gs_pipe.cv_results_)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       0.002404      0.000494         0.002791        0.000744   \n",
      "1       0.002199      0.000401         0.003002        0.000011   \n",
      "2       0.002195      0.000399         0.002801        0.000400   \n",
      "3       0.001999      0.000003         0.002800        0.000400   \n",
      "4       0.002002      0.000005         0.002801        0.000401   \n",
      "5       0.002204      0.000402         0.002598        0.000491   \n",
      "6       0.002002      0.000009         0.002599        0.000486   \n",
      "7       0.002200      0.000404         0.002203        0.000392   \n",
      "8       0.001998      0.000003         0.002999        0.000015   \n",
      "\n",
      "  param_knn__n_neighbors param_knn__p                                params  \\\n",
      "0                      3            1  {'knn__n_neighbors': 3, 'knn__p': 1}   \n",
      "1                      3            2  {'knn__n_neighbors': 3, 'knn__p': 2}   \n",
      "2                      3            3  {'knn__n_neighbors': 3, 'knn__p': 3}   \n",
      "3                      5            1  {'knn__n_neighbors': 5, 'knn__p': 1}   \n",
      "4                      5            2  {'knn__n_neighbors': 5, 'knn__p': 2}   \n",
      "5                      5            3  {'knn__n_neighbors': 5, 'knn__p': 3}   \n",
      "6                      7            1  {'knn__n_neighbors': 7, 'knn__p': 1}   \n",
      "7                      7            2  {'knn__n_neighbors': 7, 'knn__p': 2}   \n",
      "8                      7            3  {'knn__n_neighbors': 7, 'knn__p': 3}   \n",
      "\n",
      "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
      "0                1.0                1.0           0.969697           1.000000   \n",
      "1                1.0                1.0           0.969697           1.000000   \n",
      "2                1.0                1.0           0.969697           1.000000   \n",
      "3                1.0                1.0           0.969697           1.000000   \n",
      "4                1.0                1.0           0.969697           1.000000   \n",
      "5                1.0                1.0           0.969697           1.000000   \n",
      "6                1.0                1.0           0.969697           0.969697   \n",
      "7                1.0                1.0           0.969697           0.969697   \n",
      "8                1.0                1.0           0.969697           1.000000   \n",
      "\n",
      "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0                1.0         0.993939        0.012121                1  \n",
      "1                1.0         0.993939        0.012121                1  \n",
      "2                1.0         0.993939        0.012121                1  \n",
      "3                1.0         0.993939        0.012121                1  \n",
      "4                1.0         0.993939        0.012121                1  \n",
      "5                1.0         0.993939        0.012121                1  \n",
      "6                1.0         0.987879        0.014845                8  \n",
      "7                1.0         0.987879        0.014845                8  \n",
      "8                1.0         0.993939        0.012121                1  \n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_lr__C  \\\n",
      "0       0.002002      0.000013         0.001800        0.000406           1   \n",
      "1       0.007369      0.000462         0.001198        0.000404           1   \n",
      "2       0.005636      0.000526         0.001401        0.000499           1   \n",
      "3       0.002593      0.000494         0.001000        0.000001        1000   \n",
      "4       0.009239      0.000388         0.001404        0.000492        1000   \n",
      "5       0.008010      0.001289         0.001401        0.000489        1000   \n",
      "6       0.002006      0.000008         0.001196        0.000399       1e+12   \n",
      "7       0.010620      0.000592         0.001206        0.000401       1e+12   \n",
      "8       0.006600      0.000489         0.001287        0.000398       1e+12   \n",
      "\n",
      "  param_lr__fit_intercept param_lr__solver  \\\n",
      "0                   False        liblinear   \n",
      "1                   False        newton-cg   \n",
      "2                   False            lbfgs   \n",
      "3                   False        liblinear   \n",
      "4                   False        newton-cg   \n",
      "5                   False            lbfgs   \n",
      "6                   False        liblinear   \n",
      "7                   False        newton-cg   \n",
      "8                   False            lbfgs   \n",
      "\n",
      "                                              params  split0_test_score  \\\n",
      "0  {'lr__C': 1, 'lr__fit_intercept': False, 'lr__...                1.0   \n",
      "1  {'lr__C': 1, 'lr__fit_intercept': False, 'lr__...                1.0   \n",
      "2  {'lr__C': 1, 'lr__fit_intercept': False, 'lr__...                1.0   \n",
      "3  {'lr__C': 1000, 'lr__fit_intercept': False, 'l...                1.0   \n",
      "4  {'lr__C': 1000, 'lr__fit_intercept': False, 'l...                1.0   \n",
      "5  {'lr__C': 1000, 'lr__fit_intercept': False, 'l...                1.0   \n",
      "6  {'lr__C': 1000000000000.0, 'lr__fit_intercept'...                1.0   \n",
      "7  {'lr__C': 1000000000000.0, 'lr__fit_intercept'...                1.0   \n",
      "8  {'lr__C': 1000000000000.0, 'lr__fit_intercept'...                1.0   \n",
      "\n",
      "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
      "0                1.0           0.969697           0.969697           1.000000   \n",
      "1                1.0           0.969697           0.969697           1.000000   \n",
      "2                1.0           0.969697           0.969697           1.000000   \n",
      "3                1.0           0.969697           1.000000           1.000000   \n",
      "4                1.0           0.969697           1.000000           1.000000   \n",
      "5                1.0           0.969697           1.000000           1.000000   \n",
      "6                1.0           0.969697           1.000000           1.000000   \n",
      "7                1.0           0.969697           1.000000           0.969697   \n",
      "8                1.0           0.969697           1.000000           0.969697   \n",
      "\n",
      "   mean_test_score  std_test_score  rank_test_score  \n",
      "0         0.987879        0.014845                5  \n",
      "1         0.987879        0.014845                5  \n",
      "2         0.987879        0.014845                5  \n",
      "3         0.993939        0.012121                1  \n",
      "4         0.993939        0.012121                1  \n",
      "5         0.993939        0.012121                1  \n",
      "6         0.993939        0.012121                1  \n",
      "7         0.987879        0.014845                5  \n",
      "8         0.987879        0.014845                5  \n"
     ]
    }
   ],
   "source": [
    "scores = model_tests(X_train_clean, y_train, test_list)\n",
    "\n",
    "\n",
    "for x in scores:\n",
    "    \n",
    "    print(pd.DataFrame(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring some placeholder lists \n",
    "num_cols = []\n",
    "sm_cat_cols = []\n",
    "lrg_cat_cols = []\n",
    "\n",
    "col_trans = ColumnTransformer(transformers=[\n",
    "    ('numeric', num_col_pipe, num_cols),\n",
    "    ('small_cat', sm_cat_col_pipe, sm_cat_cols),\n",
    "    ('large_cat', lrg_cat_col_pipe, lrg_cat_cols )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe_knn = Pipeline(steps =[\n",
    "    ('col_trans', col_trans),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {'knn':KNeighborsClassifier(), 'lr':LogisticRegression()}\n",
    "\n",
    "def basic_model_tests(X, y, test_dict):\n",
    "    '''Takes in X and y data as well as dictionary of name:test entries to run'''\n",
    "    scores = []\n",
    "    for key, value in test_dict.items():\n",
    "        test_model_loop = Pipeline(steps=[\n",
    "            (key, value)\n",
    "        ])\n",
    "        test_model_loop.fit(X, y)\n",
    "        score = test_model_loop.score(X, y)\n",
    "        scores.append({'name':key, 'type':value, 'score':score})\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = basic_model_tests(X_train_clean, y_train, test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'knn', 'type': KNeighborsClassifier(), 'score': 0.9939759036144579}, {'name': 'lr', 'type': LogisticRegression(), 'score': 1.0}]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [{'name':'knn', 'type': KNeighborsClassifier(), 'params':{'knn__n_neighbors': [3, 5, 7], 'knn__p': [1, 2, 3]}},\n",
    "            {'name': 'lr', 'type': LogisticRegression(), 'params':{'lr__fit_intercept':[False], 'lr__C':[1, 1000, 1e12],\n",
    "                                                                  'lr__solver':['liblinear','newton-cg', 'lbfgs']}}]\n",
    "#fit_intercept=False, C= 1e12, solver='liblinear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "LogisticRegression()\n"
     ]
    }
   ],
   "source": [
    "for x in test_list:\n",
    "    print(x['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_tests(X, y, test_list):\n",
    "    '''Takes in X and y data as well as a list of dictionaries'''\n",
    "    scores = []\n",
    "    for x in test_list:\n",
    "        test_model_loop = Pipeline(steps=[\n",
    "            (x['name'], x['type'])\n",
    "        ])\n",
    "        test_model_loop.fit(X, y)\n",
    "#         score = test_model_loop.score(X, y)\n",
    "#         scores.append({'name':x['name'], 'type':x['type'], 'score':score})\n",
    "        \n",
    "        gs_pipe = GridSearchCV(estimator=test_model_loop, param_grid=x['params'])\n",
    "        gs_pipe.fit(X,y)\n",
    "        scores.append(gs_pipe.cv_results_)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       0.002404      0.000494         0.002791        0.000744   \n",
      "1       0.002199      0.000401         0.003002        0.000011   \n",
      "2       0.002195      0.000399         0.002801        0.000400   \n",
      "3       0.001999      0.000003         0.002800        0.000400   \n",
      "4       0.002002      0.000005         0.002801        0.000401   \n",
      "5       0.002204      0.000402         0.002598        0.000491   \n",
      "6       0.002002      0.000009         0.002599        0.000486   \n",
      "7       0.002200      0.000404         0.002203        0.000392   \n",
      "8       0.001998      0.000003         0.002999        0.000015   \n",
      "\n",
      "  param_knn__n_neighbors param_knn__p                                params  \\\n",
      "0                      3            1  {'knn__n_neighbors': 3, 'knn__p': 1}   \n",
      "1                      3            2  {'knn__n_neighbors': 3, 'knn__p': 2}   \n",
      "2                      3            3  {'knn__n_neighbors': 3, 'knn__p': 3}   \n",
      "3                      5            1  {'knn__n_neighbors': 5, 'knn__p': 1}   \n",
      "4                      5            2  {'knn__n_neighbors': 5, 'knn__p': 2}   \n",
      "5                      5            3  {'knn__n_neighbors': 5, 'knn__p': 3}   \n",
      "6                      7            1  {'knn__n_neighbors': 7, 'knn__p': 1}   \n",
      "7                      7            2  {'knn__n_neighbors': 7, 'knn__p': 2}   \n",
      "8                      7            3  {'knn__n_neighbors': 7, 'knn__p': 3}   \n",
      "\n",
      "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
      "0                1.0                1.0           0.969697           1.000000   \n",
      "1                1.0                1.0           0.969697           1.000000   \n",
      "2                1.0                1.0           0.969697           1.000000   \n",
      "3                1.0                1.0           0.969697           1.000000   \n",
      "4                1.0                1.0           0.969697           1.000000   \n",
      "5                1.0                1.0           0.969697           1.000000   \n",
      "6                1.0                1.0           0.969697           0.969697   \n",
      "7                1.0                1.0           0.969697           0.969697   \n",
      "8                1.0                1.0           0.969697           1.000000   \n",
      "\n",
      "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0                1.0         0.993939        0.012121                1  \n",
      "1                1.0         0.993939        0.012121                1  \n",
      "2                1.0         0.993939        0.012121                1  \n",
      "3                1.0         0.993939        0.012121                1  \n",
      "4                1.0         0.993939        0.012121                1  \n",
      "5                1.0         0.993939        0.012121                1  \n",
      "6                1.0         0.987879        0.014845                8  \n",
      "7                1.0         0.987879        0.014845                8  \n",
      "8                1.0         0.993939        0.012121                1  \n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_lr__C  \\\n",
      "0       0.002002      0.000013         0.001800        0.000406           1   \n",
      "1       0.007369      0.000462         0.001198        0.000404           1   \n",
      "2       0.005636      0.000526         0.001401        0.000499           1   \n",
      "3       0.002593      0.000494         0.001000        0.000001        1000   \n",
      "4       0.009239      0.000388         0.001404        0.000492        1000   \n",
      "5       0.008010      0.001289         0.001401        0.000489        1000   \n",
      "6       0.002006      0.000008         0.001196        0.000399       1e+12   \n",
      "7       0.010620      0.000592         0.001206        0.000401       1e+12   \n",
      "8       0.006600      0.000489         0.001287        0.000398       1e+12   \n",
      "\n",
      "  param_lr__fit_intercept param_lr__solver  \\\n",
      "0                   False        liblinear   \n",
      "1                   False        newton-cg   \n",
      "2                   False            lbfgs   \n",
      "3                   False        liblinear   \n",
      "4                   False        newton-cg   \n",
      "5                   False            lbfgs   \n",
      "6                   False        liblinear   \n",
      "7                   False        newton-cg   \n",
      "8                   False            lbfgs   \n",
      "\n",
      "                                              params  split0_test_score  \\\n",
      "0  {'lr__C': 1, 'lr__fit_intercept': False, 'lr__...                1.0   \n",
      "1  {'lr__C': 1, 'lr__fit_intercept': False, 'lr__...                1.0   \n",
      "2  {'lr__C': 1, 'lr__fit_intercept': False, 'lr__...                1.0   \n",
      "3  {'lr__C': 1000, 'lr__fit_intercept': False, 'l...                1.0   \n",
      "4  {'lr__C': 1000, 'lr__fit_intercept': False, 'l...                1.0   \n",
      "5  {'lr__C': 1000, 'lr__fit_intercept': False, 'l...                1.0   \n",
      "6  {'lr__C': 1000000000000.0, 'lr__fit_intercept'...                1.0   \n",
      "7  {'lr__C': 1000000000000.0, 'lr__fit_intercept'...                1.0   \n",
      "8  {'lr__C': 1000000000000.0, 'lr__fit_intercept'...                1.0   \n",
      "\n",
      "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
      "0                1.0           0.969697           0.969697           1.000000   \n",
      "1                1.0           0.969697           0.969697           1.000000   \n",
      "2                1.0           0.969697           0.969697           1.000000   \n",
      "3                1.0           0.969697           1.000000           1.000000   \n",
      "4                1.0           0.969697           1.000000           1.000000   \n",
      "5                1.0           0.969697           1.000000           1.000000   \n",
      "6                1.0           0.969697           1.000000           1.000000   \n",
      "7                1.0           0.969697           1.000000           0.969697   \n",
      "8                1.0           0.969697           1.000000           0.969697   \n",
      "\n",
      "   mean_test_score  std_test_score  rank_test_score  \n",
      "0         0.987879        0.014845                5  \n",
      "1         0.987879        0.014845                5  \n",
      "2         0.987879        0.014845                5  \n",
      "3         0.993939        0.012121                1  \n",
      "4         0.993939        0.012121                1  \n",
      "5         0.993939        0.012121                1  \n",
      "6         0.993939        0.012121                1  \n",
      "7         0.987879        0.014845                5  \n",
      "8         0.987879        0.014845                5  \n"
     ]
    }
   ],
   "source": [
    "scores = model_tests(X_train_clean, y_train, test_list)\n",
    "\n",
    "\n",
    "for x in scores:\n",
    "    \n",
    "    print(pd.DataFrame(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
